{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import:\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from os import stat\n",
    "import numpy as np\n",
    "\n",
    "# indexing:\n",
    "STARTING = 0\n",
    "DESTINATION = 1\n",
    "COLUMN = 0\n",
    "ROW = 1\n",
    "\n",
    "# adjustable variables:\n",
    "n_cols = 17                                     # +2 for the \"standing\" slot        # number of columns of the street\n",
    "n_rows = 17                                                                         # number of rows of the street\n",
    "num_of_pedestrian = 60                                                              # number of pedestrians\n",
    "sl_coverage = 1                                                                     # street light coverage area (excluding the light)\n",
    "md_coverage = 1                                                                     # motion detection coverage area (excluding the light)\n",
    "brightness_lvl_lowest = 1                                                           # lowest brightness level\n",
    "brightness_lvl_highest = 4                                                          # highest brightness level\n",
    "nl_opt = [[1],[0],[1]]\n",
    "actions_delay = 3                                                                   # natural light level (3 = darkest)\n",
    "episodes = 10                                                                    # total number of episodes\n",
    "alpha = 0.1                                                                         # learning rate\n",
    "gamma = 0.9                                                                         # discount factor\n",
    "custom_gamma = 0\n",
    "custom_episodes = int(episodes//15)\n",
    "epsilon_decay = 0.9999\n",
    "# bounded variables:\n",
    "positions = [(0, int(round((n_rows-1)/3))), (0, int(round((n_rows-1)*2/3))), \\\n",
    "            (0, int(round((n_cols-1)/3))), (0, int(round((n_cols-1)*2/3))), \\\n",
    "            (int(round((n_rows-1)/3)), 0), (int(round((n_rows-1)*2/3)), 0), \\\n",
    "            (int(round((n_cols-1)/3)), 0), (int(round((n_cols-1)*2/3)), 0)]                   # number of end points\n",
    "tds = list(range(1, int((num_of_pedestrian + 1)//4)))                               # list of time delay\n",
    "brightness_lvl = list(range(brightness_lvl_lowest, (brightness_lvl_highest + 1)))   # list of brightness level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PedestriansMaker():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, positions, num_of_pedestrian, tds):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.positions = positions\n",
    "        self.num_of_pedestrian = num_of_pedestrian\n",
    "        self.tds = tds\n",
    "        self.list_sd = self.create_starting_destination(self.positions)\n",
    "        self.pedestrians_sd = self.create_pedestrians_sd(self.num_of_pedestrian, self.list_sd)\n",
    "        self.pedestrians_s = self.pedestrians_sd[STARTING]\n",
    "        self.pedestrians_d = self.pedestrians_sd[DESTINATION]\n",
    "        self.pedestrians_pathway = self.create_pathway(self.pedestrians_s, self.pedestrians_d)\n",
    "        self.pedestrians_td = self.create_pedestrians_td(self.pedestrians_s, self.tds)\n",
    "  \n",
    "    @staticmethod\n",
    "    def create_starting_destination(positions):\n",
    "        starting_pt = positions # since list mentioned in the init method, can we put self.positions?\n",
    "        destination_pt = positions\n",
    "        list_sd = []\n",
    "        for starting, destination in itertools.product(starting_pt, destination_pt):\n",
    "            if starting != destination:\n",
    "                list_sd.append((starting, destination))\n",
    "        return list_sd # return a list of tuple [starting destination option]\n",
    "\n",
    "    @staticmethod\n",
    "    def create_pedestrians_sd(num_of_pedestrian, list_sd):\n",
    "        pedestrian_s = []\n",
    "        pedestrian_d = []\n",
    "        for idx_pedestrian_starting in range(num_of_pedestrian):\n",
    "            pedestrian_sd = random.choice(list_sd)\n",
    "            pedestrian_s.append(pedestrian_sd[STARTING])\n",
    "            pedestrian_d.append(pedestrian_sd[DESTINATION])\n",
    "            pedestrians_sd = [pedestrian_s, pedestrian_d]\n",
    "        return pedestrians_sd # return list of tuple [starting][destination]\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_pathway(pedestrians_s, pedestrians_d):\n",
    "        pedestrians_pathway = []\n",
    "        for idx_pedestrian in range(len(pedestrians_s)):\n",
    "            pedestrian_s = pedestrians_s[idx_pedestrian]\n",
    "            pedestrian_d = pedestrians_d[idx_pedestrian]\n",
    "            pathway_len = tuple(np.subtract(pedestrian_d, pedestrian_s))\n",
    "            pathway_len_col = pathway_len[COLUMN]\n",
    "            pathway_len_row = pathway_len[ROW]\n",
    "            pathway = ()\n",
    "            if pathway_len_col == 0:\n",
    "                pathway = pathway + (0,)\n",
    "            else:\n",
    "                pathway = pathway + (int(pathway_len_col/abs(pathway_len_col)),)\n",
    "            if pathway_len_row == 0:\n",
    "                pathway = pathway + (0,)\n",
    "            else:\n",
    "                pathway = pathway + (int(pathway_len_row/abs(pathway_len_row)),)\n",
    "            pedestrians_pathway.append(pathway)\n",
    "        return pedestrians_pathway # return the direction of a pedestrian\n",
    "\n",
    "    @staticmethod\n",
    "    def create_pedestrians_td(pedestrians_s, tds):\n",
    "        pedestrians_td = []\n",
    "        for idx_pedestrian in range(len(pedestrians_s)):\n",
    "            pedestrians_td.append(random.choice(tds))\n",
    "        return pedestrians_td # return the list of pedestrians' time delay\n",
    "    \n",
    "    @staticmethod\n",
    "    def pedestrian_loc_update(n_cols, n_rows, list_current_pedestrian, pedestrians_pathway, pedestrians_s, pedestrians_d, pedestrians_td, time):\n",
    "        updated_pedestrian_loc = []\n",
    "        for idx_pedestrian in range(len(pedestrians_pathway)):\n",
    "            pedestrian_loc = list_current_pedestrian[idx_pedestrian]\n",
    "            pedestrian_col = pedestrian_loc[COLUMN]\n",
    "            pedestrian_row = pedestrian_loc[ROW]\n",
    "            pedestrian_pathway = pedestrians_pathway[idx_pedestrian]\n",
    "            pedestrian_pathway_col = pedestrian_pathway[COLUMN]\n",
    "            pedestrian_pathway_row = pedestrian_pathway[ROW]\n",
    "            pedestrian_s = pedestrians_s[idx_pedestrian]\n",
    "            pedestrian_s_col = pedestrian_s[COLUMN]\n",
    "            pedestrian_s_row = pedestrian_s[ROW]\n",
    "            pedestrian_d = pedestrians_d[idx_pedestrian]\n",
    "            pedestrian_d_col = pedestrian_d[COLUMN]\n",
    "            pedestrian_d_row = pedestrian_d[ROW]\n",
    "            pedestrian_td = pedestrians_td[idx_pedestrian]\n",
    "            if pedestrian_loc != pedestrian_d:\n",
    "                if pedestrian_td <= time:\n",
    "                    if pedestrian_s_col == pedestrian_d_col or pedestrian_s_row == pedestrian_d_row:\n",
    "                        update_pedestrian_col = pedestrian_col + pedestrian_pathway_col\n",
    "                        update_pedestrian_row = pedestrian_row + pedestrian_pathway_row\n",
    "                        updated_pedestrian_loc.append((update_pedestrian_col, update_pedestrian_row))\n",
    "                    else:\n",
    "                        if (pedestrian_s_col == int(round(n_cols-1)/3) or pedestrian_s_col == int(round(n_cols-1)*2/3)) and \\\n",
    "                            (pedestrian_d_row == int(round(n_rows-1)/3) or pedestrian_d_row == int(round(n_rows-1)*2/3)) or \\\n",
    "                            (pedestrian_d_col == int(round(n_cols-1)/3) or pedestrian_d_col == int(round(n_cols-1)*2/3)) and \\\n",
    "                            (pedestrian_s_row == int(round(n_rows-1)/3) or pedestrian_s_row == int(round(n_rows-1)*2/3)):\n",
    "                            intersection = (pedestrian_d_col, pedestrian_s_row)\n",
    "                            intersection_col = intersection[COLUMN]\n",
    "                            intersection_row = intersection[ROW]\n",
    "                            if pedestrian_s_col == int(round(n_cols-1)/3) or pedestrian_s_col == int(round(n_cols-1)*2/3):\n",
    "                                if pedestrian_row != intersection_row:\n",
    "                                    update_pedestrian_col = pedestrian_col\n",
    "                                    update_pedestrian_row = pedestrian_row + pedestrian_pathway_row\n",
    "                                    updated_pedestrian_loc.append((update_pedestrian_col, update_pedestrian_row))  \n",
    "                                else:\n",
    "                                    update_pedestrian_col = pedestrian_col + pedestrian_pathway_col\n",
    "                                    update_pedestrian_row = pedestrian_row\n",
    "                                    updated_pedestrian_loc.append((update_pedestrian_col, update_pedestrian_row))\n",
    "                            else:\n",
    "                                if pedestrian_col != intersection_col:\n",
    "                                    update_pedestrian_col = pedestrian_col + pedestrian_pathway_col\n",
    "                                    update_pedestrian_row = pedestrian_row\n",
    "                                    updated_pedestrian_loc.append((update_pedestrian_col, update_pedestrian_row))\n",
    "                                else:\n",
    "                                    update_pedestrian_col = pedestrian_col\n",
    "                                    update_pedestrian_row = pedestrian_row + pedestrian_pathway_row \n",
    "                                    updated_pedestrian_loc.append((update_pedestrian_col, update_pedestrian_row))\n",
    "                        else:\n",
    "                            if pedestrian_s_col == int(round(n_cols-1)/3) or pedestrian_s_col == int(round(n_cols-1)*2/3):\n",
    "                                intersection1 = (pedestrian_s_col, pedestrian_s_col)\n",
    "                                intersection1_col = intersection1[COLUMN]\n",
    "                                intersection1_row = intersection1[ROW]\n",
    "                                intersection2 = (pedestrian_d_col, pedestrian_s_col)\n",
    "                                intersection2_col = intersection2[COLUMN]\n",
    "                                intersection2_row = intersection2[ROW]\n",
    "                                if pedestrian_row != intersection1_row and pedestrian_col != intersection2_col:\n",
    "                                    update_pedestrian_col = pedestrian_col\n",
    "                                    update_pedestrian_row = pedestrian_row + pedestrian_pathway_row\n",
    "                                    updated_pedestrian_loc.append((update_pedestrian_col, update_pedestrian_row))\n",
    "                                elif pedestrian_row == intersection1_row and pedestrian_col != intersection2_col:\n",
    "                                    update_pedestrian_col = pedestrian_col + pedestrian_pathway_col\n",
    "                                    update_pedestrian_row = pedestrian_row\n",
    "                                    updated_pedestrian_loc.append((update_pedestrian_col, update_pedestrian_row))\n",
    "                                else:\n",
    "                                    update_pedestrian_col = pedestrian_col\n",
    "                                    update_pedestrian_row = pedestrian_row + pedestrian_pathway_row\n",
    "                                    updated_pedestrian_loc.append((update_pedestrian_col, update_pedestrian_row))\n",
    "                            else:\n",
    "                                intersection1 = (pedestrian_s_row, pedestrian_s_row)\n",
    "                                intersection1_col = intersection1[COLUMN]\n",
    "                                intersection1_row = intersection1[ROW]\n",
    "                                intersection2 = (pedestrian_s_row, pedestrian_d_row)\n",
    "                                intersection2_col = intersection2[COLUMN]\n",
    "                                intersection2_row = intersection2[ROW]\n",
    "                                if pedestrian_col != intersection1_col and pedestrian_row != intersection2_row:\n",
    "                                    update_pedestrian_col = pedestrian_col + pedestrian_pathway_col\n",
    "                                    update_pedestrian_row = pedestrian_row\n",
    "                                    updated_pedestrian_loc.append((update_pedestrian_col, update_pedestrian_row))\n",
    "                                elif pedestrian_col == intersection1_col and pedestrian_row != intersection2_row:\n",
    "                                    update_pedestrian_col = pedestrian_col\n",
    "                                    update_pedestrian_row = pedestrian_row + pedestrian_pathway_row \n",
    "                                    updated_pedestrian_loc.append((update_pedestrian_col, update_pedestrian_row))\n",
    "                                else:\n",
    "                                    update_pedestrian_col = pedestrian_col + pedestrian_pathway_col\n",
    "                                    update_pedestrian_row = pedestrian_row\n",
    "                                    updated_pedestrian_loc.append((update_pedestrian_col, update_pedestrian_row))\n",
    "                                \n",
    "                else:\n",
    "                    updated_pedestrian_loc.append((pedestrian_col, pedestrian_row))\n",
    "            else:\n",
    "                    updated_pedestrian_loc.append((pedestrian_col, pedestrian_row))\n",
    "        return updated_pedestrian_loc # used to update the current location\n",
    "\n",
    "class StreetLightMaker():\n",
    "\n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.street = self.create_street(self.n_cols, self.n_rows)\n",
    "        self.all_sl_locs = self.create_sl(self.n_cols, self.n_rows, self.sl_coverage)\n",
    "        self.sl_locs = self.used_sl(self.all_sl_locs, self.street)\n",
    "        self.all_sls_cvrg_area = self.create_sl_coverage_area(self.n_cols, self.n_rows, self.sl_coverage, self.sl_locs)\n",
    "        self.sls_cvrg_area = self.used_sl_coverage_area(self.all_sls_cvrg_area, self.street)\n",
    "        self.all_mds_cvrg_area = self.create_motion_detection_area(self.n_cols, self.n_rows, self.md_coverage, self.sl_locs)\n",
    "        self.mds_cvrg_area = self.used_motion_detection_area(self.all_mds_cvrg_area, self.street)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_street(n_cols, n_rows):\n",
    "        street = []\n",
    "        for column in range(n_cols):\n",
    "            for row in range(n_rows):\n",
    "                coordinate = (column, row)\n",
    "                if coordinate[COLUMN] == int(round((n_cols-1)/3)) or coordinate[COLUMN] == int(round((n_cols-1)*2/3)) or \\\n",
    "                coordinate[ROW] == int(round((n_rows-1)/3)) or coordinate[ROW] == int(round((n_rows-1)*2/3)) :\n",
    "                    street.append(coordinate)\n",
    "        return street \n",
    "\n",
    "    @staticmethod\n",
    "    def create_sl(n_cols, n_rows, sl_coverage):\n",
    "        n_cols = n_cols - 2\n",
    "        n_rows = n_rows - 2\n",
    "        sl_cols = list(range((sl_coverage+1), n_cols, (sl_coverage*2+1)))\n",
    "        sl_rows = list(range((sl_coverage+1), n_rows, (sl_coverage*2+1)))\n",
    "        \n",
    "        if sl_cols == []:\n",
    "            sl_cols = [0]\n",
    "\n",
    "        if sl_rows == []:\n",
    "            sl_rows = [0]\n",
    "            \n",
    "        sl_locs = []\n",
    "        for col, row in itertools.product(sl_cols, sl_rows):\n",
    "            sl_locs.append((col, row))\n",
    "        \n",
    "        return sl_locs # return a list of tuple [street light coordinate]\n",
    "\n",
    "    @staticmethod\n",
    "    def used_sl(all_sl_locs, street):\n",
    "        used_sl_locs = []\n",
    "        for idx_sl in range(len(all_sl_locs)):\n",
    "            sl_loc = all_sl_locs[idx_sl]\n",
    "            test_coor = street.count(sl_loc)\n",
    "            if test_coor != 0:\n",
    "                used_sl_locs.append(sl_loc)\n",
    "        return used_sl_locs\n",
    "\n",
    "    @staticmethod\n",
    "    def create_sl_coverage_area(n_cols, n_rows, sl_coverage, list_sl_loc):\n",
    "        list_sl_cvrg_area = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            sl_loc = list_sl_loc[idx_sl]\n",
    "            sl_col = sl_loc[COLUMN]\n",
    "            sl_row = sl_loc[ROW]\n",
    "            coverage_col = list(range((sl_col - sl_coverage), (sl_col + sl_coverage + 1)))\n",
    "            coverage_row = list(range((sl_row - sl_coverage), (sl_row + sl_coverage + 1)))\n",
    "            cols = list(range(1, (n_cols-1)))\n",
    "            rows = list(range(1, (n_rows-1)))\n",
    "            coverage_col = list(x for x in coverage_col if x in cols)\n",
    "            coverage_row = list(x for x in coverage_row if x in rows)\n",
    "            coverage_coor = []\n",
    "            for col, row in itertools.product(coverage_col, coverage_row):\n",
    "                coverage_coor.append((col, row))\n",
    "            list_sl_cvrg_area.append(coverage_coor)\n",
    "        return list_sl_cvrg_area # return list of list of tuple\n",
    "\n",
    "    @staticmethod\n",
    "    def used_sl_coverage_area(all_sls_cvrg_area, street):\n",
    "        used_sls_cvrg_area = []\n",
    "        for idx_sl in range(len(all_sls_cvrg_area)):\n",
    "            sl = all_sls_cvrg_area[idx_sl]\n",
    "            sl_cvrg_area = []\n",
    "            for idx_cvrg in range(len(sl)):\n",
    "                cvrg_coor = sl[idx_cvrg]\n",
    "                test_coor = street.count(cvrg_coor)\n",
    "                if test_coor != 0:\n",
    "                    sl_cvrg_area.append(cvrg_coor)\n",
    "            used_sls_cvrg_area.append(sl_cvrg_area)\n",
    "        return used_sls_cvrg_area\n",
    "\n",
    "    @staticmethod\n",
    "    def create_motion_detection_area(n_cols, n_rows, md_coverage, list_sl_loc):\n",
    "        list_md_cvrg_area = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            sl_loc = list_sl_loc[idx_sl]\n",
    "            sl_col = sl_loc[COLUMN]\n",
    "            sl_row = sl_loc[ROW]\n",
    "            coverage_col = list(range((sl_col - md_coverage), (sl_col + md_coverage + 1)))\n",
    "            coverage_row = list(range((sl_row - md_coverage), (sl_row + md_coverage + 1)))\n",
    "            rows = list(range(1, n_rows - 1))\n",
    "            cols = list(range(1, n_cols - 1))\n",
    "            coverage_row = list(x for x in coverage_row if x in rows)\n",
    "            coverage_col = list(x for x in coverage_col if x in cols)\n",
    "            coverage_coor = []\n",
    "            for col, row in itertools.product(coverage_col, coverage_row):\n",
    "                coverage_coor.append((col, row))\n",
    "            list_md_cvrg_area.append(coverage_coor)\n",
    "        return list_md_cvrg_area # return list of list of tuple\n",
    "\n",
    "    @staticmethod\n",
    "    def used_motion_detection_area(all_mds_cvrg_area, street):\n",
    "        used_mds_cvrg_area = []\n",
    "        for idx_sl in range(len(all_mds_cvrg_area)):\n",
    "            sl = all_mds_cvrg_area[idx_sl]\n",
    "            sl_cvrg_area = []\n",
    "            for idx_cvrg in range(len(sl)):\n",
    "                cvrg_coor = sl[idx_cvrg]\n",
    "                test_coor = street.count(cvrg_coor)\n",
    "                if test_coor != 0:\n",
    "                    sl_cvrg_area.append(cvrg_coor)\n",
    "            used_mds_cvrg_area.append(sl_cvrg_area)\n",
    "        return used_mds_cvrg_area\n",
    "\n",
    "class Visualization():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, positions, num_of_pedestrian, tds, sl_coverage, md_coverage):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.positions = positions\n",
    "        self.num_of_pedestrian = num_of_pedestrian\n",
    "        self.tds = tds\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.PM_class = PedestriansMaker(self.n_cols, self.n_rows, self.positions, self.num_of_pedestrian, self.tds)\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        # self.grid_pedestrians = self.create_location_grid(self.n_cols, self.n_rows, self.num_of_pedestrian, self.PM_class.pedestrians_s)\n",
    "        self.grid_sls = self.create_sl_grid(self.n_cols, self.n_rows, self.SLM_class.sl_locs)\n",
    "        # self.grid_brightness = self.create_brightness_grid(action, self.n_cols, self.n_rows, self.SLM_class.list_sl_cvrg_area)\n",
    "\n",
    "    # @staticmethod\n",
    "    # def create_location_grid(n_cols, n_rows, num_of_pedestrian, pedestrians_s):\n",
    "    #     grid_pedestrian = []\n",
    "    #     for idx_row in range(n_rows):\n",
    "    #         row = []\n",
    "    #         for idx_column in range(n_cols):\n",
    "    #             row.append(0)\n",
    "    #         grid_pedestrian.append(row)\n",
    "    #     for idx_pedestrian in range(num_of_pedestrian):\n",
    "    #         pedestrian_s = pedestrians_s[idx_pedestrian]\n",
    "    #         grid_pedestrian[pedestrian_s[COLUMN]][pedestrian_s[ROW]] += 1\n",
    "    #     return grid_pedestrian # return the grid and each pedestrian position on the grid\n",
    "\n",
    "    @staticmethod\n",
    "    def create_sl_grid(n_cols, n_rows, list_sl_loc):\n",
    "        grid_sl = []\n",
    "        for idx_row in range(n_rows):\n",
    "            row = []\n",
    "            for idx_column in range(n_cols):\n",
    "                row.append(0)\n",
    "            grid_sl.append(row)\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            sl_loc = list_sl_loc[idx_sl]\n",
    "            grid_sl[sl_loc[COLUMN]][sl_loc[ROW]] = 1\n",
    "        return grid_sl # return the grid and each street light position on the grid\n",
    "\n",
    "    @staticmethod\n",
    "    def create_brightness_grid(action, n_cols, n_rows, list_sl_cvrg_area):\n",
    "        grid_sl_brightness = []\n",
    "        assert len(action) == len(list_sl_cvrg_area)\n",
    "        for idx_row in range(n_rows):\n",
    "            row = []\n",
    "            for idx_column in range(n_cols):\n",
    "                row.append(0)\n",
    "            grid_sl_brightness.append(row)\n",
    "        for idx_action in range(len(action)):\n",
    "            sl_cvrg = list_sl_cvrg_area[idx_action]\n",
    "            sl_action = action[idx_action]\n",
    "            for idx_cvrg in range(len(sl_cvrg)):\n",
    "                cvrg_coor = sl_cvrg[idx_cvrg]\n",
    "                cvrg_col = cvrg_coor[COLUMN]\n",
    "                cvrg_row = cvrg_coor[ROW]\n",
    "                grid_sl_brightness[cvrg_col][cvrg_row] = sl_action\n",
    "        return grid_sl_brightness # return grid for brightness\n",
    "\n",
    "class Environment():\n",
    "\n",
    "    def __init__(self, n_cols, n_rows, positions, num_of_pedestrian, tds, sl_coverage, md_coverage, nl_opt):\n",
    "        self.time = 0\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.positions = positions\n",
    "        self.num_of_pedestrian = num_of_pedestrian\n",
    "        self.tds = tds\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.nl_opt = nl_opt\n",
    "        self.PM_class = PedestriansMaker(self.n_cols, self.n_rows, self.positions, self.num_of_pedestrian, self.tds)\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.Vis_class = Visualization(self.n_cols, self.n_rows, self.positions, self.num_of_pedestrian, self.tds, self.sl_coverage, self.md_coverage)\n",
    "        self.list_current_pedestrian = self.PM_class.pedestrians_s.copy()\n",
    "        self.nl = self.natural_light(self.nl_opt)\n",
    "\n",
    "    @staticmethod\n",
    "    def natural_light(nl_opt):\n",
    "        period_length = n_cols + max(tds) - 1\n",
    "        period_1 = period_3 = math.floor(period_length*(0.2))\n",
    "        period_2 = period_length - period_1 - period_3\n",
    "        period = [period_1, period_2, period_3]\n",
    "        nl = []\n",
    "        for idx_nl in range(len(nl_opt)):\n",
    "            nl.append(nl_opt[idx_nl] * period[idx_nl])\n",
    "        flat_nl = [item for items in nl for item in items]\n",
    "        return flat_nl\n",
    "\n",
    "    @staticmethod\n",
    "    def pedestrian_count(list_sl_cvrg_area, list_current_pedestrian):\n",
    "        sl_pedestrian_count = []\n",
    "        for idx_sl in range(len(list_sl_cvrg_area)):\n",
    "            sl_cvrg_area = list_sl_cvrg_area[idx_sl]\n",
    "            pedestrian_count = 0\n",
    "            for idx_pedestrian in range(len(list_current_pedestrian)):\n",
    "                current_pedestrian_loc = list_current_pedestrian[idx_pedestrian]\n",
    "                test_coor = sl_cvrg_area.count((current_pedestrian_loc[COLUMN], current_pedestrian_loc[ROW]))\n",
    "                pedestrian_count = pedestrian_count + test_coor\n",
    "            if pedestrian_count >= 3: # will be generalized\n",
    "                pedestrian_count = 3\n",
    "            sl_pedestrian_count.append(pedestrian_count+1)\n",
    "        return sl_pedestrian_count\n",
    "\n",
    "    @staticmethod\n",
    "    def obs(list_sl_cvrg_area, list_current_pedestrian, nl, time):\n",
    "        list_pedestrian_detected = [nl[time]]\n",
    "        for idx_sl in range(len(list_sl_cvrg_area)):\n",
    "            sl_cvrg_area = list_sl_cvrg_area[idx_sl]\n",
    "            test_coor = 0\n",
    "            for idx_pedestrian in range(len(list_current_pedestrian)):\n",
    "                current_pedestrian_loc = list_current_pedestrian[idx_pedestrian]\n",
    "                pedestrian_count = sl_cvrg_area.count((current_pedestrian_loc[COLUMN], current_pedestrian_loc[ROW]))\n",
    "                test_coor = test_coor + pedestrian_count\n",
    "            if test_coor == 0:\n",
    "                list_pedestrian_detected.append(test_coor)\n",
    "            else:\n",
    "                list_pedestrian_detected.append(1)\n",
    "        return list_pedestrian_detected\n",
    "    \n",
    "    @staticmethod\n",
    "    def reward(actions, sl_pedestrian_count, nl, time):\n",
    "        reward_sl = []\n",
    "        for idx_sl in range(len(actions)):\n",
    "            sl_action = actions[idx_sl]\n",
    "            pedestrian_count = sl_pedestrian_count[idx_sl]\n",
    "            sl_reward = - abs(pedestrian_count - (sl_action + nl[time]))\n",
    "            reward_sl.append(sl_reward) \n",
    "        reward = sum(reward_sl)\n",
    "        return reward\n",
    "\n",
    "    @staticmethod\n",
    "    def done(list_current_pedestrian, pedestrians_d):\n",
    "        status = []\n",
    "        for idx_pedestrian in range(len(list_current_pedestrian)):\n",
    "            current_pedestrian_loc = list_current_pedestrian[idx_pedestrian]\n",
    "            pedestrian_d = pedestrians_d[idx_pedestrian]\n",
    "            if current_pedestrian_loc == pedestrian_d:\n",
    "                status.append(True)\n",
    "            else:\n",
    "                status.append(False)\n",
    "        done = all(status)\n",
    "        return done\n",
    "\n",
    "    @staticmethod\n",
    "    def info():\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        self.time = 0\n",
    "        self.PM_class = PedestriansMaker(self.n_cols, self.n_rows, self.positions, self.num_of_pedestrian, self.tds)\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.list_current_pedestrian = self.PM_class.pedestrians_s.copy()\n",
    "        list_pedestrian_detected = self.obs(self.SLM_class.sls_cvrg_area, self.list_current_pedestrian, self.nl, self.time)\n",
    "        return list_pedestrian_detected\n",
    "\n",
    "    def step(self, actions):\n",
    "        self.time = self.time + 1\n",
    "        self.list_current_pedestrian = self.PM_class.pedestrian_loc_update(self.n_cols, self.n_rows, self.list_current_pedestrian, self.PM_class.pedestrians_pathway, self.PM_class.pedestrians_s, self.PM_class.pedestrians_d, self.PM_class.pedestrians_td, self.time)\n",
    "        list_pedestrian_detected = self.obs(self.SLM_class.sls_cvrg_area, self.list_current_pedestrian, self.nl, self.time)\n",
    "        done = self.done(self.list_current_pedestrian, self.PM_class.pedestrians_d)\n",
    "        reward = self.reward(actions, self.pedestrian_count(self.SLM_class.sls_cvrg_area, self.list_current_pedestrian), self.nl, self.time)\n",
    "        info = {\n",
    "            'time' : self.time,\n",
    "            'actions' : actions,\n",
    "            'sl pedestrian count' : self.pedestrian_count(self.SLM_class.sls_cvrg_area, self.list_current_pedestrian),\n",
    "        }\n",
    "        return list_pedestrian_detected, done, reward, info # info will be added later\n",
    "\n",
    "    def render(self):\n",
    "        grid = []\n",
    "        for rows in self.Vis_class.grid_pedestrians:\n",
    "            grid.append(rows)\n",
    "        return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d75e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim3_pm = PedestriansMaker(n_cols, n_rows, positions, num_of_pedestrian, tds)\n",
    "a = sim3_pm.pedestrians_s[3]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non delay action | random\n",
    "class Agent_ndR():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            actions.append(np.random.choice(brightness_lvl))\n",
    "        return actions\n",
    "\n",
    "# non delay action | always 1\n",
    "class Agent_nd1():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            actions.append(1)\n",
    "        return actions\n",
    "\n",
    "# non delay action | always 2\n",
    "class Agent_nd2():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            actions.append(2)\n",
    "        return actions\n",
    "\n",
    "# non delay action | always 3\n",
    "class Agent_nd3():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            actions.append(3)\n",
    "        return actions\n",
    "\n",
    "# non delay action | always 4\n",
    "class Agent_nd4():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            actions.append(4)\n",
    "        return actions\n",
    "\n",
    "# non delay action | 0-1 and 1-2\n",
    "class Agent_nd12():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            if obs[idx_sl] == 0:\n",
    "                actions.append(1)\n",
    "            else:\n",
    "                actions.append(2)\n",
    "        return actions\n",
    "\n",
    "# non delay action | 0-1 and 1-3\n",
    "class Agent_nd13():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            if obs[idx_sl] == 0:\n",
    "                actions.append(1)\n",
    "            else:\n",
    "                actions.append(3)\n",
    "        return actions\n",
    "\n",
    "# non delay action | 0-1 and 1-4\n",
    "class Agent_nd14():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = 5 ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            if obs[idx_sl] == 0:\n",
    "                actions.append(1)\n",
    "            else:\n",
    "                actions.append(4)\n",
    "        return actions\n",
    "\n",
    "# non delay action | 0-1 and 1-5\n",
    "# class Agent_AZ():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = 5 ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (5 ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % 5\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // 5\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            if obs[idx_sl] == 0:\n",
    "                actions.append(1)\n",
    "            else:\n",
    "                actions.append(5)\n",
    "        return actions\n",
    "\n",
    "# non delay action | qlearning\n",
    "class Agent_ndQ():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(self.brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        state_idx = self.state_idx(obs)\n",
    "        actions_idx = np.random.choice(np.flatnonzero(qtable[state_idx, :] == qtable[state_idx, :].max()))\n",
    "        actions = self.idx_action(actions_idx, list_sl_loc, brightness_lvl)\n",
    "        return actions\n",
    "\n",
    "# non delay action | qlearning epsilon-greedy    \n",
    "class Agent_ndQe():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(self.brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        actions = []\n",
    "        if rnd < epsilon:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                actions.append(np.random.choice(brightness_lvl))\n",
    "        else:\n",
    "            state_idx = self.state_idx(obs)\n",
    "            actions_idx = np.random.choice(np.flatnonzero(qtable[state_idx, :] == qtable[state_idx, :].max()))\n",
    "            actions = self.idx_action(actions_idx, list_sl_loc, brightness_lvl)\n",
    "        return actions\n",
    "\n",
    "# delay action | random\n",
    "class Agent_dR():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                actions.append(np.random.choice(brightness_lvl))\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | always 1\n",
    "class Agent_d1():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                actions.append(1)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | always 2\n",
    "class Agent_d2():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                actions.append(2)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | always 3\n",
    "class Agent_d3():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                actions.append(3)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | always 4\n",
    "class Agent_d4():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                actions.append(4)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | 0-1 and 1-2\n",
    "class Agent_d12():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                if obs[idx_sl] == 0:\n",
    "                    actions.append(1)\n",
    "                else:\n",
    "                    actions.append(2)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | 0-1 and 1-3\n",
    "class Agent_d13():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                if obs[idx_sl] == 0:\n",
    "                    actions.append(1)\n",
    "                else:\n",
    "                    actions.append(3)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | 0-1 and 1-4\n",
    "class Agent_d14():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                if obs[idx_sl] == 0:\n",
    "                    actions.append(1)\n",
    "                else:\n",
    "                    actions.append(4)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | qlearning\n",
    "class Agent_dQ():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(self.brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, actions, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(actions, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            state_idx = self.state_idx(obs)\n",
    "            action_idx = np.random.choice(np.flatnonzero(qtable[state_idx, :] == qtable[state_idx, :].max()))\n",
    "            actions = self.idx_action(action_idx, list_sl_loc, brightness_lvl)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | qlearning epsilon-greedy \n",
    "class Agent_dQe():\n",
    "        \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = max(brightness_lvl) ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions, brightness_lvl):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (max(brightness_lvl) ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, actions, alpha, gamma, reward, new_obs, brightness_lvl):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(actions, brightness_lvl)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            if rnd < epsilon:\n",
    "                for idx_sl in range(len(list_sl_loc)):\n",
    "                    actions.append(np.random.choice(brightness_lvl))\n",
    "            else:\n",
    "                state_idx = self.state_idx(obs)\n",
    "                action_idx = np.random.choice(np.flatnonzero(qtable[state_idx, :] == qtable[state_idx, :].max()))\n",
    "                actions = self.idx_action(action_idx, list_sl_loc, brightness_lvl)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4408fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim3_pm = PedestriansMaker(n_cols, n_rows, positions, num_of_pedestrian, tds)\n",
    "sim3_slm = StreetLightMaker(n_rows, n_cols, sl_coverage, md_coverage)\n",
    "sim3_env = Environment(n_cols, n_rows, positions, num_of_pedestrian, tds, sl_coverage, md_coverage, nl_opt)\n",
    "\n",
    "sim3_agent_ndR = Agent_ndR(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_nd1 = Agent_nd1(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_nd2 = Agent_nd2(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_nd3 = Agent_nd3(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_nd4 = Agent_nd4(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_nd12 = Agent_nd12(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_nd13 = Agent_nd13(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_nd14 = Agent_nd14(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_ndQ = Agent_ndQ(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_ndQe = Agent_ndQe(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "\n",
    "sim3_agent_dR = Agent_dR(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_d1 = Agent_d1(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_d2 = Agent_d2(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_d3 = Agent_d3(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_d4 = Agent_d4(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_d12 = Agent_d12(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_d13 = Agent_d13(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_d14 = Agent_d14(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_dQ = Agent_dQ(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "sim3_agent_dQe = Agent_dQe(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd8b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non delay action | qlearning epsilon-greedy    \n",
    "class Agent_AV():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = 5 ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (5 ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        actions = []\n",
    "        if rnd < epsilon:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                actions.append(np.random.choice(brightness_lvl))\n",
    "        else:\n",
    "            state_idx = self.state_idx(obs)\n",
    "            actions_idx = np.random.choice(np.flatnonzero(qtable[state_idx, :] == qtable[state_idx, :].max()))\n",
    "            actions = self.idx_action(actions_idx, list_sl_loc, brightness_lvl)\n",
    "        return actions\n",
    "\n",
    "# non delay action | 0-1 and 1-2\n",
    "class Agent_AW():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = 5 ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (5 ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            if obs[idx_sl] == 0:\n",
    "                actions.append(1)\n",
    "            else:\n",
    "                actions.append(2)\n",
    "        return actions\n",
    "\n",
    "# non delay action | 0-1 and 1-3\n",
    "class Agent_AX():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = 5 ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (5 ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % 5\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // 5\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            if obs[idx_sl] == 0:\n",
    "                actions.append(1)\n",
    "            else:\n",
    "                actions.append(3)\n",
    "        return actions\n",
    "\n",
    "# non delay action | 0-1 and 1-4\n",
    "class Agent_AY():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = 5 ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (5 ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % 5\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // 5\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            if obs[idx_sl] == 0:\n",
    "                actions.append(1)\n",
    "            else:\n",
    "                actions.append(4)\n",
    "        return actions\n",
    "\n",
    "# non delay action | 0-1 and 1-5\n",
    "class Agent_AZ():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = 5 ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (5 ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % 5\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // 5\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, action, alpha, gamma, reward, new_obs):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(action)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        actions = []\n",
    "        for idx_sl in range(len(list_sl_loc)):\n",
    "            if obs[idx_sl] == 0:\n",
    "                actions.append(1)\n",
    "            else:\n",
    "                actions.append(5)\n",
    "        return actions\n",
    "\n",
    "# delay action | qlearning epsilon-greedy \n",
    "class Agent_BV():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = 5 ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (5 ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs, brightness_lvl): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % max(brightness_lvl)\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // max(brightness_lvl)\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, actions, alpha, gamma, reward, new_obs):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(actions)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            if rnd < epsilon:\n",
    "                for idx_sl in range(len(list_sl_loc)):\n",
    "                    actions.append(np.random.choice(brightness_lvl))\n",
    "            else:\n",
    "                state_idx = self.state_idx(obs)\n",
    "                action_idx = np.random.choice(np.flatnonzero(qtable[state_idx, :] == qtable[state_idx, :].max()))\n",
    "                actions = self.idx_action(action_idx, list_sl_loc, brightness_lvl)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | 0-1 and 1-2\n",
    "class Agent_BW():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = 5 ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (5 ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % 5\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // 5\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, actions, alpha, gamma, reward, new_obs):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(actions)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                if obs[idx_sl] == 0:\n",
    "                    actions.append(1)\n",
    "                else:\n",
    "                    actions.append(2)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | 0-1 and 1-3\n",
    "class Agent_BX():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = 5 ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (5 ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % 5\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // 5\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, actions, alpha, gamma, reward, new_obs):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(actions)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                if obs[idx_sl] == 0:\n",
    "                    actions.append(1)\n",
    "                else:\n",
    "                    actions.append(3)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | 0-1 and 1-4\n",
    "class Agent_BY():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = 5 ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (5 ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % 5\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // 5\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, actions, alpha, gamma, reward, new_obs):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(actions)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                if obs[idx_sl] == 0:\n",
    "                    actions.append(1)\n",
    "                else:\n",
    "                    actions.append(4)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions\n",
    "\n",
    "# delay action | 0-1 and 1-5\n",
    "class Agent_BZ():\n",
    "    \n",
    "    def __init__(self, n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay):\n",
    "        self.n_cols = n_cols\n",
    "        self.n_rows = n_rows\n",
    "        self.sl_coverage = sl_coverage\n",
    "        self.md_coverage = md_coverage\n",
    "        self.brightness_lvl = brightness_lvl\n",
    "        self.actions_delay = actions_delay\n",
    "        self.SLM_class = StreetLightMaker(self.n_cols, self.n_rows, self.sl_coverage, self.md_coverage)\n",
    "        self.state_space = 2 ** (len(self.SLM_class.sl_locs)+1)\n",
    "        self.action_space = 5 ** len(self.SLM_class.sl_locs)\n",
    "        self.qtable = np.zeros([self.state_space, self.action_space])\n",
    "    \n",
    "    @staticmethod\n",
    "    def state_idx(state):\n",
    "        state_bin = ''.join(map(str,state))\n",
    "        state_idx = 0\n",
    "        for idx in range(len(state_bin)):\n",
    "            i = len(state_bin) - 1 - idx\n",
    "            state_idx += int(state_bin[i]) * (2 ** idx)\n",
    "        return state_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_state(state_idx, list_sl_loc):\n",
    "        state = np.zeros(len(list_sl_loc+1))\n",
    "        state_bin = list(bin(state_idx))\n",
    "        del state_bin[0:2]\n",
    "        state_bin = list(map(int, state_bin))\n",
    "        for idx_bin in range(len(state_bin)):\n",
    "            state_len = len(list_sl_loc+1)\n",
    "            idx = state_len - 1 - idx_bin\n",
    "            idx_bin = len(state_bin) - 1 - idx_bin\n",
    "            state[idx] = state_bin[idx_bin]\n",
    "        return state\n",
    "\n",
    "    @staticmethod\n",
    "    def action_idx(actions):\n",
    "        actions_copy = np.array(actions)\n",
    "        actions_copy.fill(1)\n",
    "        actions_update = actions - actions_copy\n",
    "        actions_ter = ''.join(map(str, actions_update))\n",
    "        actions_idx = 0\n",
    "        for idx in range(len(actions_ter)):\n",
    "            i = len(actions_ter) - 1 - idx\n",
    "            actions_idx += int(actions_ter[i]) * (5 ** idx)\n",
    "        return actions_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def idx_action(actions_idx, sl_locs): # currently not used\n",
    "        actions_ter = np.zeros(len(sl_locs))\n",
    "        current_idx = actions_idx\n",
    "        for idx in range(len(actions_ter)):\n",
    "            reminder = current_idx % 5\n",
    "            actions_ter[len(actions_ter) - 1 - idx] = reminder\n",
    "            current_idx = current_idx // 5\n",
    "        action_copy = np.array(actions_ter)\n",
    "        action_copy.fill(1)\n",
    "        action = actions_ter + action_copy\n",
    "        return list(map(int, action))\n",
    "        \n",
    "    def learn(self, qtable, obs, actions, alpha, gamma, reward, new_obs):\n",
    "        state_idx = self.state_idx(obs)\n",
    "        action_idx = self.action_idx(actions)\n",
    "        new_state_idx = self.state_idx(new_obs)\n",
    "        old_value = qtable[state_idx, action_idx]\n",
    "        qtable[state_idx, action_idx] = old_value + (alpha * (reward + (gamma * np.max(qtable[new_state_idx, :])) - old_value))\n",
    "        return qtable\n",
    "\n",
    "    def action(self, actions, time, actions_delay, qtable, obs, list_sl_loc, brightness_lvl, epsilon):\n",
    "        rnd = np.random.random()\n",
    "        old_actions = actions\n",
    "        actions = []\n",
    "        if time % self.actions_delay == 0:\n",
    "            for idx_sl in range(len(list_sl_loc)):\n",
    "                if obs[idx_sl] == 0:\n",
    "                    actions.append(1)\n",
    "                else:\n",
    "                    actions.append(5)\n",
    "        else:\n",
    "            actions = old_actions\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e01d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = PedestriansMaker(n_cols, n_rows, positions, num_of_pedestrian, tds, intersection)\n",
    "slm = StreetLightMaker(n_rows, n_cols, sl_coverage, md_coverage)\n",
    "env = Environment(n_cols, n_rows, positions, num_of_pedestrian, tds, intersection, sl_coverage, md_coverage, nl_opt)\n",
    "agent_av = Agent_AV(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "agent_aw = Agent_AW(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "agent_ax = Agent_AX(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "agent_ay = Agent_AY(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "agent_az = Agent_AZ(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "agent_bv = Agent_BV(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "agent_bw = Agent_BW(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "agent_bx = Agent_BX(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "agent_by = Agent_BY(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)\n",
    "agent_bz = Agent_BZ(n_cols, n_rows, sl_coverage, md_coverage, brightness_lvl, actions_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(21)\n",
    "print('final test - non delay action | qlearning epsilon-greedy')\n",
    "\n",
    "qtable = agent_av.qtable\n",
    "epsilon = 1\n",
    "full_actions = []\n",
    "full_rewards = []\n",
    "epsilons = []\n",
    "for i in range(episodes):\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    episode_actions = []\n",
    "    epsilon = epsilon * epsilon_decay\n",
    "    while not done:\n",
    "        actions = agent_av.action(qtable, obs, agent_av.SLM_class.sl_locs, brightness_lvl, epsilon)\n",
    "        new_obs, done, reward, info = env.step(actions)\n",
    "        total_reward += reward\n",
    "        qtable = agent_av.learn(qtable, obs, actions, alpha, custom_gamma, reward, new_obs)\n",
    "        obs = new_obs\n",
    "        episode_actions.append(\",\".join([str(x) for x in actions]))\n",
    "    full_actions.append(\"|\".join([str(x) for x in episode_actions]))\n",
    "    full_rewards.append(total_reward)\n",
    "    epsilons.append(epsilon)\n",
    "\n",
    "rewards_mean_av = []\n",
    "for idx in range(0, episodes, episodes//200):\n",
    "    mean = np.mean(full_rewards[idx : idx + 200])\n",
    "    rewards_mean_av.append(mean)\n",
    "\n",
    "epsilons_av = []\n",
    "for idx in range(0, episodes, episodes//200):\n",
    "    mean = np.mean(epsilons[idx : idx + 200])\n",
    "    epsilons_av.append(mean)\n",
    "\n",
    "plt.plot(list(range(len(rewards_mean_av))), rewards_mean_av)\n",
    "plt.title(\"Trend of Reward - Non Delay Action | QLearning Epsilon-Greedy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de02b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(21)\n",
    "print('final test - non delay action | 0-1 and 1-2')\n",
    "\n",
    "qtable = agent_aw.qtable\n",
    "epsilon = 1\n",
    "full_actions = []\n",
    "full_rewards = []\n",
    "for i in range(custom_episodes):\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    episode_actions = []\n",
    "    epsilon = epsilon * epsilon_decay\n",
    "    while not done:\n",
    "        actions = agent_aw.action(qtable, obs, agent_aw.SLM_class.sl_locs, brightness_lvl, epsilon)\n",
    "        new_obs, done, reward, info = env.step(actions)\n",
    "        total_reward += reward\n",
    "        qtable = agent_aw.learn(qtable, obs, actions, alpha, custom_gamma, reward, new_obs)\n",
    "        obs = new_obs\n",
    "        episode_actions.append(\",\".join([str(x) for x in actions]))\n",
    "    full_actions.append(\"|\".join([str(x) for x in episode_actions]))\n",
    "    full_rewards.append(total_reward)\n",
    "\n",
    "rewards_mean_aw = []\n",
    "for idx in range(0, custom_episodes, custom_episodes//200):\n",
    "    mean = np.mean(full_rewards[idx : idx + 200])\n",
    "    rewards_mean_aw.append(mean)\n",
    "\n",
    "plt.plot(list(range(len(rewards_mean_aw))), rewards_mean_aw)\n",
    "plt.title(\"Trend of Reward - Non Delay Action | 0-1 and 1-2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390c0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(21)\n",
    "print('final test - non delay action | 0-1 and 1-3')\n",
    "\n",
    "qtable = agent_ax.qtable\n",
    "epsilon = 1\n",
    "full_actions = []\n",
    "full_rewards = []\n",
    "for i in range(custom_episodes):\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    episode_actions = []\n",
    "    epsilon = epsilon * epsilon_decay\n",
    "    while not done:\n",
    "        actions = agent_ax.action(qtable, obs, agent_ax.SLM_class.sl_locs, brightness_lvl, epsilon)\n",
    "        new_obs, done, reward, info = env.step(actions)\n",
    "        total_reward += reward\n",
    "        qtable = agent_ax.learn(qtable, obs, actions, alpha, custom_gamma, reward, new_obs)\n",
    "        obs = new_obs\n",
    "        episode_actions.append(\",\".join([str(x) for x in actions]))\n",
    "    full_actions.append(\"|\".join([str(x) for x in episode_actions]))\n",
    "    full_rewards.append(total_reward)\n",
    "\n",
    "rewards_mean_ax = []\n",
    "for idx in range(0, custom_episodes, custom_episodes//200):\n",
    "    mean = np.mean(full_rewards[idx : idx + 200])\n",
    "    rewards_mean_ax.append(mean)\n",
    "\n",
    "plt.plot(list(range(len(rewards_mean_ax))), rewards_mean_ax)\n",
    "plt.title(\"Trend of Reward - Non Delay Action | 0-1 and 1-3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(21)\n",
    "print('final test - non delay action | 0-1 and 1-4')\n",
    "\n",
    "qtable = agent_ay.qtable\n",
    "epsilon = 1\n",
    "full_actions = []\n",
    "full_rewards = []\n",
    "for i in range(custom_episodes):\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    episode_actions = []\n",
    "    epsilon = epsilon * epsilon_decay\n",
    "    while not done:\n",
    "        actions = agent_ay.action(qtable, obs, agent_ay.SLM_class.sl_locs, brightness_lvl, epsilon)\n",
    "        new_obs, done, reward, info = env.step(actions)\n",
    "        total_reward += reward\n",
    "        qtable = agent_ay.learn(qtable, obs, actions, alpha, custom_gamma, reward, new_obs)\n",
    "        obs = new_obs\n",
    "        episode_actions.append(\",\".join([str(x) for x in actions]))\n",
    "    full_actions.append(\"|\".join([str(x) for x in episode_actions]))\n",
    "    full_rewards.append(total_reward)\n",
    "\n",
    "rewards_mean_ay = []\n",
    "for idx in range(0, custom_episodes, custom_episodes//200):\n",
    "    mean = np.mean(full_rewards[idx : idx + 200])\n",
    "    rewards_mean_ay.append(mean)\n",
    "\n",
    "plt.plot(list(range(len(rewards_mean_ay))), rewards_mean_ay)\n",
    "plt.title(\"Trend of Reward - Non Delay Action | 0-1 and 1-4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf83913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(21)\n",
    "# print('final test - non delay action | 0-1 and 1-5')\n",
    "\n",
    "# qtable = agent_az.qtable\n",
    "# epsilon = 1\n",
    "# full_actions = []\n",
    "# full_rewards = []\n",
    "# for i in range(custom_episodes):\n",
    "#     total_reward = 0\n",
    "#     done = False\n",
    "#     obs = env.reset()\n",
    "#     episode_actions = []\n",
    "#     epsilon = epsilon * epsilon_decay\n",
    "#     while not done:\n",
    "#         actions = agent_az.action(qtable, obs, agent_az.SLM_class.sl_locs, brightness_lvl, epsilon)\n",
    "#         new_obs, done, reward, info = env.step(actions)\n",
    "#         total_reward += reward\n",
    "#         qtable = agent_az.learn(qtable, obs, actions, alpha, custom_gamma, reward, new_obs)\n",
    "#         obs = new_obs\n",
    "#         episode_actions.append(\",\".join([str(x) for x in actions]))\n",
    "#     full_actions.append(\"|\".join([str(x) for x in episode_actions]))\n",
    "#     full_rewards.append(total_reward)\n",
    "\n",
    "# rewards_mean_az = []\n",
    "# for idx in range(0, custom_episodes, custom_episodes//200):\n",
    "#     mean = np.mean(full_rewards[idx : idx + 200])\n",
    "#     rewards_mean_az.append(mean)\n",
    "\n",
    "# plt.plot(list(range(len(rewards_mean_az))), rewards_mean_az)\n",
    "# plt.title(\"Trend of Reward - Non Delay Action | 0-1 and 1-5\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(21)\n",
    "print('final test - delay action | qlearning epsilon-greedy')\n",
    "\n",
    "qtable = agent_bv.qtable\n",
    "epsilon = 1\n",
    "full_actions = []\n",
    "full_rewards = []\n",
    "epsilons = []\n",
    "for i in range(episodes):\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    actions = [1 for _ in range(len(agent_bv.SLM_class.sl_locs))]\n",
    "    episode_actions = []\n",
    "    epsilon = epsilon * epsilon_decay\n",
    "    while not done:\n",
    "        actions = agent_bv.action(actions, env.time, actions_delay, qtable, obs, agent_bv.SLM_class.sl_locs, brightness_lvl, epsilon)\n",
    "        new_obs, done, reward, info = env.step(actions)\n",
    "        total_reward += reward\n",
    "        qtable = agent_bv.learn(qtable, obs, actions, alpha, gamma, reward, new_obs)\n",
    "        obs = new_obs\n",
    "        episode_actions.append(\",\".join([str(x) for x in actions]))\n",
    "    full_actions.append(\"|\".join([str(x) for x in episode_actions]))\n",
    "    full_rewards.append(total_reward)\n",
    "    epsilons.append(epsilon)\n",
    "\n",
    "rewards_mean_bv = []\n",
    "for idx in range(0, episodes, episodes//200):\n",
    "    mean = np.mean(full_rewards[idx : idx + 200])\n",
    "    rewards_mean_bv.append(mean)\n",
    "\n",
    "epsilons_bv = []\n",
    "for idx in range(0, episodes, episodes//200):\n",
    "    mean = np.mean(epsilons[idx : idx + 200])\n",
    "    epsilons_bv.append(mean)\n",
    "\n",
    "plt.plot(list(range(len(rewards_mean_bv))), rewards_mean_bv)\n",
    "plt.title(\"Trend of Reward - Delay Action | QLearning Epsilon-Greedy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(21)\n",
    "print('final test - delay action | 0-1 and 1-2')\n",
    "\n",
    "qtable = agent_bw.qtable\n",
    "epsilon = 1\n",
    "full_actions = []\n",
    "full_rewards = []\n",
    "for i in range(custom_episodes):\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    actions = [1 for _ in range(len(agent_bw.SLM_class.sl_locs))]\n",
    "    episode_actions = []\n",
    "    epsilon = epsilon * epsilon_decay\n",
    "    while not done:\n",
    "        actions = agent_bw.action(actions, env.time, actions_delay, qtable, obs, agent_bw.SLM_class.sl_locs, brightness_lvl, epsilon)\n",
    "        new_obs, done, reward, info = env.step(actions)\n",
    "        total_reward += reward\n",
    "        qtable = agent_bw.learn(qtable, obs, actions, alpha, gamma, reward, new_obs)\n",
    "        obs = new_obs\n",
    "        episode_actions.append(\",\".join([str(x) for x in actions]))\n",
    "    full_actions.append(\"|\".join([str(x) for x in episode_actions]))\n",
    "    full_rewards.append(total_reward)\n",
    "\n",
    "rewards_mean_bw = []\n",
    "for idx in range(0, custom_episodes, custom_episodes//200):\n",
    "    mean = np.mean(full_rewards[idx : idx + 200])\n",
    "    rewards_mean_bw.append(mean)\n",
    "\n",
    "plt.plot(list(range(len(rewards_mean_bw))), rewards_mean_bw)\n",
    "plt.title(\"Trend of Reward - Delay Action | 0-1 and 1-2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884bd49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(21)\n",
    "print('final test - delay action | 0-1 and 1-3')\n",
    "\n",
    "qtable = agent_bx.qtable\n",
    "epsilon = 1\n",
    "full_actions = []\n",
    "full_rewards = []\n",
    "for i in range(custom_episodes):\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    actions = [1 for _ in range(len(agent_bx.SLM_class.sl_locs))]\n",
    "    episode_actions = []\n",
    "    epsilon = epsilon * epsilon_decay\n",
    "    while not done:\n",
    "        actions = agent_bx.action(actions, env.time, actions_delay, qtable, obs, agent_bx.SLM_class.sl_locs, brightness_lvl, epsilon)\n",
    "        new_obs, done, reward, info = env.step(actions)\n",
    "        total_reward += reward\n",
    "        qtable = agent_bx.learn(qtable, obs, actions, alpha, gamma, reward, new_obs)\n",
    "        obs = new_obs\n",
    "        episode_actions.append(\",\".join([str(x) for x in actions]))\n",
    "    full_actions.append(\"|\".join([str(x) for x in episode_actions]))\n",
    "    full_rewards.append(total_reward)\n",
    "\n",
    "rewards_mean_bx = []\n",
    "for idx in range(0, custom_episodes, custom_episodes//200):\n",
    "    mean = np.mean(full_rewards[idx : idx + 200])\n",
    "    rewards_mean_bx.append(mean)\n",
    "\n",
    "plt.plot(list(range(len(rewards_mean_bx))), rewards_mean_bx)\n",
    "plt.title(\"Trend of Reward - Delay Action | 0-1 and 1-3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6548e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(21)\n",
    "print('final test - delay action | 0-1 and 1-4')\n",
    "\n",
    "qtable = agent_by.qtable\n",
    "epsilon = 1\n",
    "full_actions = []\n",
    "full_rewards = []\n",
    "for i in range(custom_episodes):\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    actions = [1 for _ in range(len(agent_by.SLM_class.sl_locs))]\n",
    "    episode_actions = []\n",
    "    epsilon = epsilon * epsilon_decay\n",
    "    while not done:\n",
    "        actions = agent_by.action(actions, env.time, actions_delay, qtable, obs, agent_by.SLM_class.sl_locs, brightness_lvl, epsilon)\n",
    "        new_obs, done, reward, info = env.step(actions)\n",
    "        total_reward += reward\n",
    "        qtable = agent_by.learn(qtable, obs, actions, alpha, gamma, reward, new_obs)\n",
    "        obs = new_obs\n",
    "        episode_actions.append(\",\".join([str(x) for x in actions]))\n",
    "    full_actions.append(\"|\".join([str(x) for x in episode_actions]))\n",
    "    full_rewards.append(total_reward)\n",
    "\n",
    "rewards_mean_by = []\n",
    "for idx in range(0, custom_episodes, custom_episodes//200):\n",
    "    mean = np.mean(full_rewards[idx : idx + 200])\n",
    "    rewards_mean_by.append(mean)\n",
    "\n",
    "plt.plot(list(range(len(rewards_mean_by))), rewards_mean_by)\n",
    "plt.title(\"Trend of Reward - Delay Action | 0-1 and 1-4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(21)\n",
    "# print('final test - delay action | 0-1 and 1-5')\n",
    "\n",
    "# qtable = agent_bz.qtable\n",
    "# epsilon = 1\n",
    "# full_actions = []\n",
    "# full_rewards = []\n",
    "# for i in range(custom_episodes):\n",
    "#     total_reward = 0\n",
    "#     done = False\n",
    "#     obs = env.reset()\n",
    "#     actions = [1 for _ in range(len(agent_bz.SLM_class.sl_locs))]\n",
    "#     episode_actions = []\n",
    "#     epsilon = epsilon * epsilon_decay\n",
    "#     while not done:\n",
    "#         actions = agent_bz.action(actions, env.time, actions_delay, qtable, obs, agent_bz.SLM_class.sl_locs, brightness_lvl, epsilon)\n",
    "#         new_obs, done, reward, info = env.step(actions)\n",
    "#         total_reward += reward\n",
    "#         qtable = agent_bz.learn(qtable, obs, actions, alpha, gamma, reward, new_obs)\n",
    "#         obs = new_obs\n",
    "#         episode_actions.append(\",\".join([str(x) for x in actions]))\n",
    "#     full_actions.append(\"|\".join([str(x) for x in episode_actions]))\n",
    "#     full_rewards.append(total_reward)\n",
    "\n",
    "# rewards_mean_bz = []\n",
    "# for idx in range(0, custom_episodes, custom_episodes//200):\n",
    "#     mean = np.mean(full_rewards[idx : idx + 200])\n",
    "#     rewards_mean_bz.append(mean)\n",
    "\n",
    "# plt.plot(list(range(len(rewards_mean_bz))), rewards_mean_bz)\n",
    "# plt.title(\"Trend of Reward - Delay Action | 0-1 and 1-5\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b688b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "av = rewards_mean_av\n",
    "aw = rewards_mean_aw\n",
    "ax_x = rewards_mean_ax\n",
    "ay = rewards_mean_ay\n",
    "# az = rewards_mean_az\n",
    "bv = rewards_mean_bv\n",
    "bw = rewards_mean_bw\n",
    "bx = rewards_mean_bx\n",
    "by = rewards_mean_by\n",
    "# bz = rewards_mean_bz\n",
    "\n",
    "fig_1, ax_1 = plt.subplots(nrows = 2, ncols=1, figsize=(20, 10))\n",
    "\n",
    "ax_1[0].plot(list(range(len(av))), av, color = \"red\", alpha = 0.7)\n",
    "ax_1[0].plot(list(range(len(aw))), aw, color = \"purple\", alpha = 0.7)\n",
    "ax_1[0].plot(list(range(len(ax_x))), ax_x, color = \"orange\", alpha = 0.7)\n",
    "ax_1[0].plot(list(range(len(ay))), ay, color = \"blue\", alpha = 0.7)\n",
    "# ax_1[0].plot(list(range(len(az))), az, color = \"green\", alpha = 0.7)\n",
    "ax_1[0].set_title(\"Trend of Reward\")\n",
    "ax_1[0].set_ylabel(\"Mean Rewards\")\n",
    "\n",
    "ax_1[1].plot(list(range(len(bv))), bv, color = \"red\", alpha = 0.7)\n",
    "ax_1[1].plot(list(range(len(bw))), bw, color = \"purple\", alpha = 0.7)\n",
    "ax_1[1].plot(list(range(len(bx))), bx, color = \"orange\", alpha = 0.7)\n",
    "ax_1[1].plot(list(range(len(by))), by, color = \"blue\", alpha = 0.7)\n",
    "# ax_1[1].plot(list(range(len(bz))), bz, color = \"green\", alpha = 0.7)\n",
    "ax_1[1].set_title(\"Trend of Reward\")\n",
    "ax_1[1].set_ylabel(\"Mean Rewards\")\n",
    "\n",
    "fig_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilons_av = epsilons_av\n",
    "# epsilons_bv = epsilons_bv\n",
    "\n",
    "# fig_2, ax_2 = plt.subplots(nrows = 1, ncols=1, figsize=(20, 10))\n",
    "\n",
    "# ax_2[0].plot(list(range(len(epsilons_av))), epsilons_av, color = \"red\", alpha = 0.7)\n",
    "# ax_2[0].plot(list(range(len(epsilons_bv))), epsilons_bv, color = \"purple\", alpha = 0.7)\n",
    "# ax_2[0].set_title(\"Trend of Epsilons\")\n",
    "# ax_2[0].set_ylabel(\"Epsilon Value\")\n",
    "\n",
    "# fig_2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
